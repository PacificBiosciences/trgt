{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b6e2db-22aa-4088-96f5-91053bf91d1a",
   "metadata": {},
   "source": [
    "A workflow for flagging unusually long repeat expansions in probands.\n",
    "1. Get the repeat length in proband and in 100 HPRC samples\n",
    "2. Save the repeat if it is significantly longer in the proband relative to controls\n",
    "3. Output the resulting list of repeats to a TSV file and generate some summary plots\n",
    "\n",
    "The first example will perform the query when our proband is merged into a single database. Our second example is for situations where the sample of interest is not in the same database as the controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1716b47-df1f-430f-a720-5badb8f6ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trgt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3b25fb-dacd-4531-922d-80dfb7639027",
   "metadata": {},
   "outputs": [],
   "source": [
    "hprc = trgt.load_tdb(\"../test_files/databases/hprc_105.tdb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564b7c51-2233-46a4-babc-fba0ea861e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprc sample count: 105\n"
     ]
    }
   ],
   "source": [
    "print(\"hprc sample count:\", len(hprc[\"sample\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe9c93-ffbb-46b1-850c-16eacfe9cbbd",
   "metadata": {},
   "source": [
    "First, we'll want to build a method that will pull all samples' observed allele lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b1e7f1c-ca55-4805-9bb3-de68606b0f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observed_allele_lengths(allele_table, sample_table):\n",
    "    \"\"\"\n",
    "    Given allele and sample tables, return the observed allele lengths\n",
    "    allele_table must already be indexed by \"LocusID\" and \"allele_number\"\n",
    "    \"\"\"\n",
    "    idx_table = pd.MultiIndex.from_frame(sample_table[[\"LocusID\", \"allele_number\"]])\n",
    "    return allele_table.loc[idx_table, [\"allele_length\"]]\n",
    "\n",
    "# Only need to do this once\n",
    "alleles = hprc[\"allele\"].set_index([\"LocusID\", \"allele_number\"])\n",
    "observed_allele_lengths = []\n",
    "for name, table in hprc[\"sample\"].items():\n",
    "    result = get_observed_allele_lengths(alleles, table)\n",
    "    result['sample_name'] = name\n",
    "    observed_allele_lengths.append(result)\n",
    "\n",
    "observed_allele_lengths = pd.concat(observed_allele_lengths).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b5f94d8-41bc-430b-8191-667a378fbf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed 195866982 alleles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocusID</th>\n",
       "      <th>allele_number</th>\n",
       "      <th>allele_length</th>\n",
       "      <th>sample_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>HG002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>HG002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>HG002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>HG002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "      <td>HG002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocusID  allele_number  allele_length sample_name\n",
       "0        5              0             94       HG002\n",
       "1        5              0             94       HG002\n",
       "2        6              0             91       HG002\n",
       "3        6              0             91       HG002\n",
       "4        7              3            167       HG002"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Observed {len(observed_allele_lengths)} alleles\")\n",
    "observed_allele_lengths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd9e71-55a9-4afa-b82b-7a6e19dabe0a",
   "metadata": {},
   "source": [
    "For every locus, we want to calculate the numbers about the observed allele lengths which we'll be testing against. We'll simply calculate the mean and standard deviation. If you have a custom method, switch the '.describe' to `.apply(your_method)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a877ffd-416a-467a-b98a-40278dd3dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_distribution = (observed_allele_lengths\n",
    "                           .groupby([\"LocusID\"])[\"allele_length\"]\n",
    "                           .describe()[[\"mean\", \"std\"]])\n",
    "length_distribution['upper_threshold'] = length_distribution['mean'] + length_distribution['std'] * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f35954-5d8a-4b1a-bfa4-8a54866b8429",
   "metadata": {},
   "source": [
    "Calculating this length distribution is slow. If you're planning on running this test at scale, it probably makes sense to save the length distribution so that you can reuse it in the future.\n",
    "\n",
    "For now, we're going to subset to our sample of interests' allele lengths and then pull out the interesting loci where the allele length is greater than the upper threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "49655f5a-d1eb-4d1c-af63-35b4dbfc3cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4947 interesting loci\n"
     ]
    }
   ],
   "source": [
    "proband_name = \"HG002\"\n",
    "proband_lengths = (observed_allele_lengths[\n",
    "                            observed_allele_lengths['sample_name'] == proband_name\n",
    "                        ].set_index([\"LocusID\"])\n",
    "                        .join(length_distribution))\n",
    "\n",
    "interesting_loci = proband_lengths[proband_lengths[\"allele_length\"] > proband_lengths[\"upper_threshold\"]]\n",
    "print(f\"Found {len(interesting_loci)} interesting loci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0379358b-1cac-46ec-a736-3d1119bbfc85",
   "metadata": {},
   "source": [
    "To make a final report, we'll join the Locus information to the interesting loci so we know where these things happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3da38019-47c7-417d-9863-8fe349eed60f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocus\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mset_index([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocusId\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mjoin(interesting_loci, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m output\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "output = data['locus'].set_index([\"LocusId\"]).join(interesting_loci, how='right')\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d67fc8-e7c7-4143-9a90-a86094811b65",
   "metadata": {},
   "source": [
    "And to save that report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f01a32-99b2-49e9-a9ab-0aff40309de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"proband_only.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e96adb-773d-4b2b-b185-41ac46c492a4",
   "metadata": {},
   "source": [
    "The above example worked on a TRGTdb where the sample of interest was already merged in. If the reference samples are in a different database from the sample of interest, there's two possible workflows:\n",
    "1. Including the sample while building the `length_distribution`\n",
    "2. Excluding the sample while building the `length_distribution`\n",
    "\n",
    "Workflow 1 is simple. All we need to do is consolidate the sample of interest into a `merged_database`, and then rerun the steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b1aea1-f7de-425f-ad10-c86482159e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "proband = trgt.load_tdb(\"../test_files/databases/son.tdb/\")\n",
    "# Note that this creates the database in-memory. Therefore, no `.tdb` files are altered\n",
    "merged_database = trgt.tdb_consolidate(hprc, proband)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf832ccb-408a-4169-933c-ab6a4e5876a4",
   "metadata": {},
   "source": [
    "Workflow 2 is slightly more complex. You could create a `merged_database` and rerun the steps above after modifying the `length_distribution` calculation to exclude the sample of interest before performing the `.groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f0720-5ebd-49fb-90de-8b857b0535d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_distribution = (observed_allele_lengths\n",
    "                           [observed_allele_lengths[\"sample_name\"] != proband_name]\n",
    "                           .groupby([\"LocusID\"])[\"allele_length\"]\n",
    "                           .describe()[[\"mean\", \"std\"]])\n",
    "length_distribution['upper_threshold'] = length_distribution['mean'] + length_distribution['std'] * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d613419-6213-494d-a2e9-6064cd5d7edd",
   "metadata": {},
   "source": [
    "Alternatively, if you've saved the precomputed `length_distribution` with per-locus identifying information (i.e. chrom,start,end), you can do the following steps:\n",
    "1. Load the `length_distribution`\n",
    "2. Set its index to the chromosome, start, and end\n",
    "3. Run `get_observed_allele_lengths` on the proband sample's TRGTdb.\n",
    "4. Create an index on the proband's `observed_lengths` by joining to the proband's locus columns\n",
    "5. Join the proband's `observed_length` to the precomputed `length_distribution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f401909-3bdb-4f25-9afa-f9fd31848395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
